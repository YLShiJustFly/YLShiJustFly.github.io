<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Thinking about 3FS  - Friends&#39; Life and Work Space</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="YLShi" /><meta name="description" content="Rise to Prominence: 3FS In the past two months, DeepSeek&amp;rsquo;s popularity has skyrocketed. What particularly delights us storage professionals is that DeepSeek has brought distributed storage, which has long been hidden away, to the forefront.
The GitHub attention that 3FS has received is unprecedented among open-source distributed storage projects, and there probably won&amp;rsquo;t be another like it.
The star count in just 3 days after open-sourcing exceeded that of numerous open-source storage projects that have been cultivating for years." /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.100.2 with theme even" />


<link rel="canonical" href="http://YLShiJustFly.github.io/post/from.deepseek-3fs.to.ai.storage/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Thinking about 3FS " />
<meta property="og:description" content="Rise to Prominence: 3FS In the past two months, DeepSeek&rsquo;s popularity has skyrocketed. What particularly delights us storage professionals is that DeepSeek has brought distributed storage, which has long been hidden away, to the forefront.
The GitHub attention that 3FS has received is unprecedented among open-source distributed storage projects, and there probably won&rsquo;t be another like it.
The star count in just 3 days after open-sourcing exceeded that of numerous open-source storage projects that have been cultivating for years." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://YLShiJustFly.github.io/post/from.deepseek-3fs.to.ai.storage/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2025-05-30T14:17:59+08:00" />
<meta property="article:modified_time" content="2025-05-30T14:17:59+08:00" />

<meta itemprop="name" content="Thinking about 3FS ">
<meta itemprop="description" content="Rise to Prominence: 3FS In the past two months, DeepSeek&rsquo;s popularity has skyrocketed. What particularly delights us storage professionals is that DeepSeek has brought distributed storage, which has long been hidden away, to the forefront.
The GitHub attention that 3FS has received is unprecedented among open-source distributed storage projects, and there probably won&rsquo;t be another like it.
The star count in just 3 days after open-sourcing exceeded that of numerous open-source storage projects that have been cultivating for years."><meta itemprop="datePublished" content="2025-05-30T14:17:59+08:00" />
<meta itemprop="dateModified" content="2025-05-30T14:17:59+08:00" />
<meta itemprop="wordCount" content="1584">
<meta itemprop="keywords" content="ceph,3FS," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Thinking about 3FS "/>
<meta name="twitter:description" content="Rise to Prominence: 3FS In the past two months, DeepSeek&rsquo;s popularity has skyrocketed. What particularly delights us storage professionals is that DeepSeek has brought distributed storage, which has long been hidden away, to the forefront.
The GitHub attention that 3FS has received is unprecedented among open-source distributed storage projects, and there probably won&rsquo;t be another like it.
The star count in just 3 days after open-sourcing exceeded that of numerous open-source storage projects that have been cultivating for years."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Friends&#39; Life and Work Space</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Friends&#39; Life and Work Space</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Thinking about 3FS </h1>

      <div class="post-meta">
        <span class="post-time"> 2025-05-30 </span>
        <div class="post-category">
            <a href="/categories/ceph/"> ceph </a>
            </div>
          <span class="more-meta"> 1584 words </span>
          <span class="more-meta"> 8 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#rise-to-prominence-3fs">Rise to Prominence: 3FS</a></li>
    <li><a href="#what-kind-of-storage-does-ai-need">What Kind of Storage Does AI Need?</a></li>
    <li><a href="#ai-training-framework--storage-integration">AI Training Framework + Storage Integration</a></li>
    <li><a href="#ai-training-phases-and-storage-requirements">AI Training Phases and Storage Requirements</a></li>
    <li><a href="#ai-and-cephfs">AI and CephFS</a>
      <ul>
        <li><a href="#advantages-of-cephfs-in-ai-applications">Advantages of CephFS in AI Applications</a></li>
        <li><a href="#cephfs-disadvantages">CephFS Disadvantages</a></li>
        <li><a href="#possible-cephfs-optimizations">Possible CephFS Optimizations</a></li>
      </ul>
    </li>
    <li><a href="#typical-ai-storage-systems">Typical AI Storage Systems</a></li>
    <li><a href="#current-status-of-3fs">Current Status of 3FS</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="rise-to-prominence-3fs">Rise to Prominence: 3FS</h1>
<p>In the past two months, DeepSeek&rsquo;s popularity has skyrocketed. What particularly delights us storage professionals is that DeepSeek has brought distributed storage, which has long been hidden away, to the forefront.</p>
<p>The GitHub attention that 3FS has received is unprecedented among open-source distributed storage projects, and there probably won&rsquo;t be another like it.</p>
<p>The star count in just 3 days after open-sourcing exceeded that of numerous open-source storage projects that have been cultivating for years. Social media and various technical discussion groups are filled with discussions about 3FS.</p>
<p>So I&rsquo;m also jumping on the bandwagon, though I mainly don&rsquo;t want to discuss 3FS itself, but rather discuss the storage behind large models and the storage systems I actually use frequently in AI applications. After all, there are already many technical articles discussing 3FS, and with such excellent predecessors, I won&rsquo;t embarrass myself.</p>
<ul>
<li>
<p><a href="https://mp.weixin.qq.com/s/RWCbpIBmHCzGNroFhbm2oA">DeepSeek 3FS: End-to-End Cacheless Storage New Paradigm</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/ozjrPppaLB5Voam4KIUWaw">Real Test of DeepSeek 3FS: We Disassembled the Violent Aesthetics of the Performance Monster</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/B_5xdV2gl9APcJyBuBuUgQ">Deepseek 3FS (Fire-Flyer File System) Design Notes</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/Ri9-sjsaoQ3LUE2-dTAN_g">Real Testing of DeepSeek Open Source 3FS Based on eRDMA</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/n_cvZVGMfgKkgCSGX7K3kA">DeepSeek 3FS Interpretation and Source Code Analysis (1): The Way of Efficient Training</a></p>
</li>
</ul>
<h1 id="what-kind-of-storage-does-ai-need">What Kind of Storage Does AI Need?</h1>
<p>This is actually an age-old question, and there are many high-quality articles online. However, there seems to be little content that connects AI and storage step by step (maybe I just haven&rsquo;t found the relevant content, but it doesn&rsquo;t matter, organizing this article is mainly to help myself sort out knowledge in this area). Let&rsquo;s set this aside for now and expand on it step by step later.</p>
<h1 id="ai-training-framework--storage-integration">AI Training Framework + Storage Integration</h1>
<p>When discussing AI storage, we can&rsquo;t avoid AI training frameworks. Storage has always been just a castle in the air - without OpenStack, without Kubernetes, without AI training frameworks, storage cannot be implemented.</p>
<p>Current mainstream AI training frameworks include PyTorch, TensorFlow, and PaddlePaddle. Here we use PyTorch as an example. PyTorch provides two data primitives: torch.utils.data.Dataset and torch.utils.data.DataLoader. PyTorch data loading is completed through Dataset+DataLoader, where Dataset defines the data format and data transformation forms, and DataLoader continuously reads batch data in an iterative manner.</p>
<p>You can implement flexible data reading by inheriting PyTorch&rsquo;s own Dataset class. Various systems can implement data connections (Connectors) with PyTorch based on this.</p>
<p>The following shows the overall framework diagram. The S3 Connector and FS-S3 Connector shown below are both developed by AWS (details can be found in aws-connector-for-pytorch). The Amazon S3 Connector for PyTorch automatically optimizes S3 read and list requests to improve data loading and checkpoint performance for training workloads. Due to S3&rsquo;s universality, object storage systems that support S3 can directly use the Amazon S3 Connector for PyTorch. FS-S3 uses S3 at the bottom layer and can be exported through the file system, which is also a popular type of system currently, combining the advantages of both fs and s3. File-Store Connector is the system that PyTorch supports by default. In addition to these, there are also some public cloud&rsquo;s own Connectors.</p>
<p><img src="../../image/pytorch-connector.png" alt="An example"></p>
<ul>
<li>AWS S3 Connector Usage Example</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">s3torchconnector</span> <span class="kn">import</span> <span class="n">S3MapDataset</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Build training dataset based on AWS S3 Connector</span>
</span></span><span class="line"><span class="cl"><span class="n">uri</span> <span class="o">=</span> <span class="s1">&#39;s3://mnist/train&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">aws_region</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;AWS_REGION&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">S3MapDataset</span><span class="o">.</span><span class="n">from_prefix</span><span class="p">(</span><span class="n">uri</span><span class="p">,</span> <span class="n">region</span><span class="o">=</span><span class="n">aws_region</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">transform</span><span class="o">=</span><span class="n">MNISTTransform</span><span class="p">(</span><span class="n">transform</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Training data loading</span>
</span></span><span class="line"><span class="cl"><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>File-Store Connector Usage Example</li>
</ul>
<p>File-Store Connector is the system that PyTorch supports by default, used as follows:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data.Dataset</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Load dataset based on given directory,</span>
</span></span><span class="line"><span class="cl"><span class="c1"># so the directory can be a local file system directory or a distributed file system directory mounted locally</span>
</span></span><span class="line"><span class="cl"><span class="n">imagenet_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageNet</span><span class="p">(</span><span class="s1">&#39;path/to/imagenet_root/&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">imagenet_data</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                          <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">nThreads</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>Alibaba Cloud OSS Connector Usage Example</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">osstorchconnector</span> <span class="kn">import</span> <span class="n">OssMapDataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">ENDPOINT</span> <span class="o">=</span> <span class="s2">&#34;http://oss-cn-beijing-internal.aliyuncs.com&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">CONFIG_PATH</span> <span class="o">=</span> <span class="s2">&#34;/etc/oss-connector/config.test.json&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">CRED_PATH</span> <span class="o">=</span> <span class="s2">&#34;/root/.alibabacloud/credentials&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">OSS_URI</span> <span class="o">=</span> <span class="s2">&#34;oss://ai-testset/EnglistImg/Img/BadImag/Bmp/Sample001/&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl"> <span class="n">data</span> <span class="o">=</span> <span class="nb">object</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"> <span class="k">return</span> <span class="nb">object</span><span class="o">.</span><span class="n">key</span><span class="p">,</span> <span class="nb">object</span><span class="o">.</span><span class="n">label</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Use OssMapDataset&#39;s from_prefix method to build Dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">map_dataset</span> <span class="o">=</span> <span class="n">OssMapDataset</span><span class="o">.</span><span class="n">from_prefix</span><span class="p">(</span><span class="n">OSS_URI</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="n">ENDPOINT</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span><span class="n">cred_path</span><span class="o">=</span><span class="n">CRED_PATH</span><span class="p">,</span> <span class="n">config_path</span><span class="o">=</span><span class="n">CONFIG_PATH</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create PyTorch data loader based on map_dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">map_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">prefetch_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Use data in training loop</span>
</span></span><span class="line"><span class="cl"><span class="c1"># for batch in loader:</span>
</span></span><span class="line"><span class="cl">     <span class="c1"># Perform training operations</span>
</span></span><span class="line"><span class="cl">   <span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="ai-training-phases-and-storage-requirements">AI Training Phases and Storage Requirements</h1>
<p>AI training mainly includes data collection &amp; preprocessing storage; model development; model training; model inference phases. The general storage requirements for each phase are as follows. <a href="https://developer.baidu.com/article/detail.html?id=417144">This Baidu article provides a good introduction to this phase</a></p>
<p><img src="../../image/AIFlow-storage.jpg" alt="An example"></p>
<p>Here we focus on the relationship between training and storage: For training, there may be multiple iterations (epochs). Within each epoch, the dataset first needs to be shuffled randomly, then the shuffled data is divided into several batches. Each time a batch of data is read, one training iteration is performed. Checkpoints are also saved periodically for fast failure recovery:</p>
<p><img src="../../image/Ai-train.jpg" alt="An example"></p>
<p>So the storage requirements for AI training are roughly as follows:</p>
<ol>
<li>
<p>The shuffle phase is a pure metadata operation process:
Main file system metadata requests include readdir + getattr:</p>
<ul>
<li>Get dentry metadata information of subdirectories through readdir</li>
<li>Then get the file&rsquo;s inode through getattr, which can then be used to read and write files</li>
</ul>
</li>
<li>
<p>The data reading process mainly tests the storage system&rsquo;s read capability</p>
</li>
<li>
<p>CheckPoint: A single node&rsquo;s checkpoint for large models can typically reach tens to hundreds of GB. Multiple training nodes write simultaneously, and need to read simultaneously when recovering.
Since Checkpoint is a single large file (each GPU has one CheckPoint under parallel GPU training), when writing CheckPoint, the storage system&rsquo;s write bandwidth capability is required; when recovering, the storage system&rsquo;s read bandwidth capability is required.</p>
</li>
</ol>
<p>So for AI training, random write capability for small files is not the most important. The most important are the storage system&rsquo;s metadata processing capability, read-write bandwidth capability, or read IOPS capability (if the training model involves a large number of small files).</p>
<h1 id="ai-and-cephfs">AI and CephFS</h1>
<h2 id="advantages-of-cephfs-in-ai-applications">Advantages of CephFS in AI Applications</h2>
<ul>
<li>
<p>Bandwidth Capability
Ceph&rsquo;s underlying storage engine, compared to other Raft-based distributed storage systems, doesn&rsquo;t have the double-write problem (AI scenarios involve large writes), thus providing excellent data bandwidth capability.</p>
</li>
<li>
<p>Linear Scaling
Ceph provides excellent linear scaling capability for both capacity and performance. A single cluster can support tens of thousands of hard drives.</p>
</li>
<li>
<p>Stability
After all these years, Ceph&rsquo;s stability is quite reliable. A cluster can sit there for months without management and probably won&rsquo;t have any problems (of course, don&rsquo;t mess around with it).</p>
</li>
<li>
<p>Maintainability
Ceph supports Prometheus, Grafana, and has a web console. Ceph has also developed numerous metrics and tools.</p>
</li>
<li>
<p>Functionality
Nothing more to say, it&rsquo;s all about being comprehensive.</p>
</li>
<li>
<p>Strong Consistency
Provides multi-write capability for the same file. This might be its biggest feature compared to other distributed file systems on the market, as most file systems only support CTO (close to open semantics).
Of course, this strong consistency also brings disadvantages, which we&rsquo;ll discuss below.</p>
</li>
<li>
<p>Supports both kernel and FUSE modes
Most other open-source file systems are FUSE-based.</p>
</li>
</ul>
<h2 id="cephfs-disadvantages">CephFS Disadvantages</h2>
<ul>
<li>
<p>Metadata Consistency Issues &amp; Lock Problems
Ceph&rsquo;s strong consistency may bring serious metadata performance issues. For example: if Client A is currently writing a file (it holds the write buffer cap for this file), and Client B also wants to access this file, then to ensure data consistency, MDS will require Client A to flush all its write buffers to the underlying data pool. If the write buffer data is large, or if the network capability between Client A and backend storage is not particularly good, this flush time may be quite long. During this process, A is always waiting for locks, which is a classic type of metadata performance issue in CephFS. We often see alerts like &ldquo;fail to lock&rdquo;.</p>
</li>
<li>
<p>MDS Single-threaded Problem
MDS processes IO in a single thread, and all metadata requests from clients are first placed in a queue and processed one by one.</p>
</li>
<li>
<p>Metadata Scalability Issues
Metadata cannot scale linearly. Current newer generation file systems, such as CubeFS, Alibaba&rsquo;s InitFS, Baidu&rsquo;s CFS, etc., all have metadata clusters that can scale linearly.
Although CephFS can use multiple MDS, the dynamic balancing of multiple MDS doesn&rsquo;t seem very stable yet. Generally, manual pinning is used, which increases operational complexity.</p>
</li>
<li>
<p>High Latency for Small Write IOPS in Data Operations
Due to the long chain on the OSD side, as well as locks, including BlueStore single-threaded flush and other reasons, the latency of individual IOs cannot be very low. Of course, in AI scenarios, small write latency is not a very important metric.</p>
</li>
<li>
<p>High Difficulty
No explanation needed, those who understand will understand.</p>
</li>
</ul>
<h2 id="possible-cephfs-optimizations">Possible CephFS Optimizations</h2>
<ul>
<li>Use multiple MDS</li>
<li>Try to use cache (MDS cache &amp; OSD cache)</li>
<li>Deploy MDS and metadata pool OSDs on the same machine</li>
<li>Consider using lazyio functionality</li>
<li>Reduce small file operations: preprocess data into formats like TFRecords</li>
</ul>
<h1 id="typical-ai-storage-systems">Typical AI Storage Systems</h1>
<table>
<thead>
<tr>
<th>Storage Type</th>
<th>Representative Systems</th>
</tr>
</thead>
<tbody>
<tr>
<td>Local File System</td>
<td>NVME + Local File System (xfs, ext4, zfs, etc.)</td>
</tr>
<tr>
<td>Distributed File System</td>
<td>3FS, CephFS, DAOS, CubeFS, Lustre</td>
</tr>
<tr>
<td>Object Storage</td>
<td>Minio, S3, NVIDIA/Aistore</td>
</tr>
<tr>
<td>File Gateway + Object Storage</td>
<td>JuiceFS, Alluxio, CurveFS</td>
</tr>
<tr>
<td>Vector Database</td>
<td>Milvus</td>
</tr>
<tr>
<td>Commercial Storage</td>
<td>VAST DATA, WeakFS, YRCloudFile, Baidu Canghai CFS</td>
</tr>
</tbody>
</table>
<h1 id="current-status-of-3fs">Current Status of 3FS</h1>
<p>3FS is really hot. Finally, let me briefly describe the current status of 3FS that I know of around me: companies like Ant Group, Xiaohongshu, ByteDance, China Unicom, etc. are all actively preparing environments for real testing.</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">YLShi</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2025-05-30
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/ceph/">ceph</a>
          <a href="/tags/3fs/">3FS</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/ceph-content/distributed-storage/en/from.deepseek-3fs.to.ai.storage/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Thinking about 3FS </span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/obsidian&#43;git-pages%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/">
            <span class="next-text nav-default">Obsidian &#43; Git pages自动部署博客系统搭建 </span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="YLShiJustFly/YLShiJustFly.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:youseeicanfly@126.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.zhihu.com/people/tan-xi-liu-nian" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="http://YLShiJustFly.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2022 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span>YLShi</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.191509a5c8442abdb6eb5020a332fd59bdd83a7e78a2d2241108df9113504292.js"></script>








</body>
</html>
